{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AC-GAN_Edited.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_sjladBF3QT",
        "colab_type": "text"
      },
      "source": [
        "**Problem3 AC-GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EyOJDFZrRMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.initializers import RandomNormal\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyqKUekwF8HN",
        "colab_type": "text"
      },
      "source": [
        "**Import necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juugSGWcrl2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_diagram(disc_real, disc_fake, gen_loss, epoch):\n",
        "  plt.figure(figsize=(15, 6))\n",
        "  plt.plot(list(range(1, epoch + 2)),disc_real, linewidth=3)\n",
        "  plt.plot(list(range(1, epoch + 2)),disc_fake, linewidth=3)\n",
        "  plt.plot(list(range(1, epoch + 2)),gen_loss, linewidth=3)\n",
        "  plt.legend(['disc_real','disc_fake','gen_loss'])\n",
        "\n",
        "  plt.title(\"Loss Values\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.xticks(list(range(1, epoch + 1)))\n",
        "  plt.xlabel('epoch')\n",
        "  plt.grid(which='both', axis='both')\n",
        "  plt.savefig('/content/drive/My Drive/NeuralNet/Q3/AC_GAN/Plots/plot_Epoch_%d.png' % epoch, bbox_inches='tight')\n",
        "  plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_m96kZNGCaj",
        "colab_type": "text"
      },
      "source": [
        "**Loss-Function Diagram**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6i1rNDCHnJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(32,32,3), n_classes=10):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # image input\n",
        "  in_image = Input(shape=in_shape)\n",
        "  fe = Conv2D(16, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Dropout(0.5)(fe)\n",
        "  fe = Conv2D(32, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(in_image)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Dropout(0.5)(fe)\n",
        "  fe = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n",
        "  fe = BatchNormalization()(fe)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Dropout(0.5)(fe)\n",
        "  fe = Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(fe)\n",
        "  fe = BatchNormalization()(fe)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Dropout(0.5)(fe)\n",
        "  fe = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(fe)\n",
        "  fe = BatchNormalization()(fe)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Dropout(0.5)(fe)\n",
        "  fe = Conv2D(512, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(fe)\n",
        "  fe = BatchNormalization()(fe)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Dropout(0.5)(fe)\n",
        "  # flatten feature maps\n",
        "  fe = Flatten()(fe)\n",
        "  # real/fake output\n",
        "  out1 = Dense(1, activation='sigmoid')(fe)\n",
        "  # class label output\n",
        "  out2 = Dense(n_classes, activation='softmax')(fe)\n",
        "  # define model\n",
        "  model = Model(in_image, [out1, out2])\n",
        "  # compile model\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uNuSLZqHoxn",
        "colab_type": "text"
      },
      "source": [
        "**Define Discriminator: Someone can find detail descriotion of this architecture in Mini-Project Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLE6-32nH2po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_generator(latent_dim, n_classes=10):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # label input\n",
        "  in_label = Input(shape=(1,))\n",
        "  # embedding for categorical input\n",
        "  li = Embedding(n_classes, 50)(in_label)\n",
        "  # linear multiplication\n",
        "  n_nodes = 8 * 8 * 3\n",
        "  li = Dense(n_nodes, kernel_initializer=init)(li)\n",
        "  # reshape to additional channel\n",
        "  li = Reshape((8, 8, 3))(li)\n",
        "  # image generator input\n",
        "  in_lat = Input(shape=(latent_dim,))\n",
        "  n_nodes = 384 * 8 * 8\n",
        "  gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
        "  gen = Activation('relu')(gen)\n",
        "  gen = Reshape((8, 8, 384))(gen)\n",
        "  # merge image gen and label input\n",
        "  merge = Concatenate()([gen, li])\n",
        "  gen = Conv2DTranspose(192, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
        "  gen = BatchNormalization()(gen)\n",
        "  gen = Activation('relu')(gen)\n",
        "  gen = Conv2DTranspose(96, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
        "  gen = BatchNormalization()(gen)\n",
        "  gen = Activation('relu')(gen)\n",
        "  gen = Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "  out_layer = Activation('tanh')(gen)\n",
        "  model = Model([in_lat, in_label], out_layer)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2bAALZH52F",
        "colab_type": "text"
      },
      "source": [
        "**Define Generator: This part we implement architecture of the paper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmh3FZ9BIGJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "  # Freez Dicriminator\n",
        "  d_model.trainable = False\n",
        "  gan_output = d_model(g_model.output)\n",
        "  model = Model(g_model.input, gan_output)\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu8O1gqhIG60",
        "colab_type": "text"
      },
      "source": [
        "**Define AC-GAN Model by merging Generator and Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKv6Zj2XIWVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_real_samples():\n",
        "  # load dataset\n",
        "  (trainX, trainy), (_, _) = cifar10.load_data()\n",
        "  X = trainX\n",
        "  X = X.astype('float32')\n",
        "  X = (X - 127.5) / 127.5\n",
        "  print(X.shape, trainy.shape)\n",
        "  return [X, trainy]\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "  images, labels = dataset\n",
        "  ix = randint(0, images.shape[0], n_samples)\n",
        "  X, labels = images[ix], labels[ix]\n",
        "  y = ones((n_samples, 1))\n",
        "  return [X, labels], y\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "  x_input = randn(latent_dim * n_samples)\n",
        "  z_input = x_input.reshape(n_samples, latent_dim)\n",
        "  labels = randint(0, n_classes, n_samples)\n",
        "  return [z_input, labels]\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "  z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "  images = generator.predict([z_input, labels_input])\n",
        "  y = zeros((n_samples, 1))\n",
        "  return [images, labels_input], y\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "  [X, _], _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "  fig, axs = plt.subplots(10, 10, figsize=(15,15))\n",
        "  plt.subplots_adjust(hspace=0.0, wspace=0.0)\n",
        "  NUMBER_PER_CLASS = 10\n",
        "  for classlabel in range(10):\n",
        "    gen_imgs = X\n",
        "    for i in range(NUMBER_PER_CLASS):\n",
        "         #Dont scale the images back, let keras handle it#\n",
        "         img = image.array_to_img(gen_imgs[classlabel*10 + i], scale=True)\n",
        "         axs[i,classlabel].imshow(img)\n",
        "         axs[i,classlabel].axis('off')\n",
        "  fig.savefig('/content/drive/My Drive/NeuralNet/Q3/AC_GAN/Epoch_%d.png' % step, bbox_inches='tight')\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQKh7L15IXYX",
        "colab_type": "text"
      },
      "source": [
        "**Some useful functions for loading and preprocessing the data and genrate output of Generator and plot diagrams and outputs if Generator part**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trveACh2pWWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b23a2dc2-9813-4c62-cd73-62aac7d80705"
      },
      "source": [
        "\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=500, n_batch=64):\n",
        "  bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  # calculate the size of half a batch of samples\n",
        "  half_batch = int(n_batch / 2)\n",
        "  disc_real_tmp = 0\n",
        "  disc_fake_tmp = 0\n",
        "  _epoch = 0\n",
        "  gen_tmp = 0\n",
        "  disc_real = []\n",
        "  disc_fake = []\n",
        "  gen_loss = []\n",
        "  for i in range(n_steps):\n",
        "    # get randomly selected 'real' samples\n",
        "    [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
        "    # update discriminator model weights\n",
        "    _,d_r1,d_r2 = d_model.train_on_batch(X_real, [y_real, labels_real])\n",
        "    # generate 'fake' examples\n",
        "    [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "    # update discriminator model weights\n",
        "    _,d_f,d_f2 = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n",
        "    # prepare points in latent space as input for the generator\n",
        "    [z_input, z_labels] = generate_latent_points(latent_dim, n_batch)\n",
        "    # create inverted labels for the fake samples\n",
        "    y_gan = ones((n_batch, 1))\n",
        "    # update the generator via the discriminator's error\n",
        "    _,g_1,g_2 = gan_model.train_on_batch([z_input, z_labels], [y_gan, z_labels])\n",
        "    disc_real_tmp += d_r2\n",
        "    disc_fake_tmp += d_f2\n",
        "    gen_tmp += g_2\n",
        "\n",
        "    if (i+1)%bat_per_epo == 0:\n",
        "      disc_real.append(disc_real_tmp/bat_per_epo)\n",
        "      disc_fake.append(disc_fake_tmp/bat_per_epo)\n",
        "      gen_loss.append(gen_tmp/bat_per_epo)\n",
        "      summarize_performance(i, g_model, latent_dim)\n",
        "      plot_diagram(disc_real, disc_fake, gen_loss, _epoch)\n",
        "      disc_real_tmp = 0\n",
        "      disc_fake_tmp = 0\n",
        "      gen_tmp = 0\n",
        "      _epoch +=1\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, dataset, latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "Epoch:  2\n",
            "Epoch:  3\n",
            "Epoch:  4\n",
            "Epoch:  5\n",
            "Epoch:  6\n",
            "Epoch:  7\n",
            "Epoch:  8\n",
            "Epoch:  9\n",
            "Epoch:  10\n",
            "Epoch:  11\n",
            "Epoch:  12\n",
            "Epoch:  13\n",
            "Epoch:  14\n",
            "Epoch:  15\n",
            "Epoch:  16\n",
            "Epoch:  17\n",
            "Epoch:  18\n",
            "Epoch:  19\n",
            "Epoch:  20\n",
            "Epoch:  21\n",
            "Epoch:  22\n",
            "Epoch:  23\n",
            "Epoch:  24\n",
            "Epoch:  25\n",
            "Epoch:  26\n",
            "Epoch:  27\n",
            "Epoch:  28\n",
            "Epoch:  29\n",
            "Epoch:  30\n",
            "Epoch:  31\n",
            "Epoch:  32\n",
            "Epoch:  33\n",
            "Epoch:  34\n",
            "Epoch:  35\n",
            "Epoch:  36\n",
            "Epoch:  37\n",
            "Epoch:  38\n",
            "Epoch:  39\n",
            "Epoch:  40\n",
            "Epoch:  41\n",
            "Epoch:  42\n",
            "Epoch:  43\n",
            "Epoch:  44\n",
            "Epoch:  45\n",
            "Epoch:  46\n",
            "Epoch:  47\n",
            "Epoch:  48\n",
            "Epoch:  49\n",
            "Epoch:  50\n",
            "Epoch:  51\n",
            "Epoch:  52\n",
            "Epoch:  53\n",
            "Epoch:  54\n",
            "Epoch:  55\n",
            "Epoch:  56\n",
            "Epoch:  57\n",
            "Epoch:  58\n",
            "Epoch:  59\n",
            "Epoch:  60\n",
            "Epoch:  61\n",
            "Epoch:  62\n",
            "Epoch:  63\n",
            "Epoch:  64\n",
            "Epoch:  65\n",
            "Epoch:  66\n",
            "Epoch:  67\n",
            "Epoch:  68\n",
            "Epoch:  69\n",
            "Epoch:  70\n",
            "Epoch:  71\n",
            "Epoch:  72\n",
            "Epoch:  73\n",
            "Epoch:  74\n",
            "Epoch:  75\n",
            "Epoch:  76\n",
            "Epoch:  77\n",
            "Epoch:  78\n",
            "Epoch:  79\n",
            "Epoch:  80\n",
            "Epoch:  81\n",
            "Epoch:  82\n",
            "Epoch:  83\n",
            "Epoch:  84\n",
            "Epoch:  85\n",
            "Epoch:  86\n",
            "Epoch:  87\n",
            "Epoch:  88\n",
            "Epoch:  89\n",
            "Epoch:  90\n",
            "Epoch:  91\n",
            "Epoch:  92\n",
            "Epoch:  93\n",
            "Epoch:  94\n",
            "Epoch:  95\n",
            "Epoch:  96\n",
            "Epoch:  97\n",
            "Epoch:  98\n",
            "Epoch:  99\n",
            "Epoch:  100\n",
            "Epoch:  101\n",
            "Epoch:  102\n",
            "Epoch:  103\n",
            "Epoch:  104\n",
            "Epoch:  105\n",
            "Epoch:  106\n",
            "Epoch:  107\n",
            "Epoch:  108\n",
            "Epoch:  109\n",
            "Epoch:  110\n",
            "Epoch:  111\n",
            "Epoch:  112\n",
            "Epoch:  113\n",
            "Epoch:  114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fskiqb2XItDw",
        "colab_type": "text"
      },
      "source": [
        "**Train Model in 500 Epoch. in each batch we must first train Discriminator on real and fake images. Then by freezing Discriminaotr(In gan function we freezed them) train the Generator.**"
      ]
    }
  ]
}